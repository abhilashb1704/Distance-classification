{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10851626,"sourceType":"datasetVersion","datasetId":6739806},{"sourceId":10853445,"sourceType":"datasetVersion","datasetId":6741166}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Instructions\n###### Follow the instructions given in comments prefixed with ## and write your code below that.\n###### Also fill the partial code in given blanks. \n###### Don't make any changes to the rest part of the codes\n\n### Answer the questions given at the end of this notebook within your report.\n\n\n### You would need to submit your GitHub repository link. Refer to the Section 6: Final Submission on the PDF document for the details.\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\nfrom matplotlib.offsetbox import OffsetImage, AnnotationBbox","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T16:06:44.555107Z","iopub.execute_input":"2025-02-26T16:06:44.555333Z","iopub.status.idle":"2025-02-26T16:06:47.953053Z","shell.execute_reply.started":"2025-02-26T16:06:44.555311Z","shell.execute_reply":"2025-02-26T16:06:47.951857Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import cv2\nimport os\n\n# Correct file path\nimage_path = \"/kaggle/input/faculty1/Plaksha_Faculty.jpg\"\n\n# Verify file existence\nif not os.path.exists(image_path):\n    print(\"Error: Image file not found!\")\n    exit()\n\n# Load image in color and grayscale\nimg = cv2.imread(image_path)\nimg1 = cv2.imread(image_path, 0)\n\n# Ensure images are loaded properly\nif img is None or img1 is None:\n    print(\"Error: Image not loaded. Check file path.\")\n    exit()\n\n# Load the Haar Cascade classifier\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n\n# Detect faces\nfaces_rect = face_cascade.detectMultiScale(img1, 1.05, 4, minSize=(25, 25), maxSize=(50, 50))\n\n# Draw rectangles around detected faces\nfor (x, y, w, h) in faces_rect:\n    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n    cv2.putText(img, \"Face\", (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n\n# Show result\nif len(faces_rect) > 0:\n    cv2.imshow(f\"Total faces detected: {len(faces_rect)}\", img)\n    cv2.waitKey(0)\n    cv2.destroyAllWindows()\nelse:\n    print(\"No faces detected.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-26T16:06:47.954150Z","iopub.execute_input":"2025-02-26T16:06:47.954524Z","execution_failed":"2025-02-26T16:06:54.073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n# Extract face region features (Hue and Saturation)\nimg_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  ## call the img and convert it from BGR to HSV and store in img_hsv\nhue_saturation = []\nface_images = []  # To store detected face images\n\nfor (x, y, w, h) in faces_rect:\n    face = img_hsv[y:y + h, x:x + w]\n    hue = np.mean(face[:, :, 0])\n    saturation = np.mean(face[:, :, 1])\n    hue_saturation.append((hue, saturation))\n    face_images.append(face)\n\nhue_saturation = np.array(hue_saturation)\n\n## Perform k-Means clustering on hue_saturation and store in kmeans\nkmeans = KMeans(n_clusters=3, random_state=42).fit(hue_saturation)\n#centroids = kmeans.cluster_centers_\n#labels = kmeans.labels_\n\n# Create a figure and axis\nfig, ax = plt.subplots(figsize=(12, 6))\n\n# Plot the clustered faces with custom markers\nfor i, (x, y, w, h) in enumerate(faces_rect):\n    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n    ax.add_artist(ab)\n    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1])\n\n## Put x label\nplt.xlabel(\"Hue\")\n## Put y label\nplt.ylabel(\"Saturation\")\n## Put title\nplt.title(\"K-Means Clustering of Face Hue and Saturation\")\n## Put grid\nplt.grid(True)\n## show the plot \nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-26T16:06:54.073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create an empty list to store legend labels\nlegend_labels = []\n\n# Create lists to store points for each cluster\ncluster_0_points = []\ncluster_1_points = []\n\n# Your code for scatter plot goes here\nfig, ax = plt.subplots(figsize=(12, 6))\nfor i, (x, y, w, h) in enumerate(faces_rect):\n    if kmeans.labels_[i] == 0:\n        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n    else:\n        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n\ncluster_0_points = np.array(cluster_0_points)\n# Plot points for cluster 0 in green\nplt.scatter(cluster_0_points[:, 0], cluster_0_points[:, 1], color='green', label='Cluster 0')\n\ncluster_1_points = np.array(cluster_1_points)\n# Plot points for cluster 1 in blue\nplt.scatter(cluster_1_points[:, 0], cluster_1_points[:, 1], color='blue', label='Cluster 1')\n\n# Calculate and plot centroids\ncentroid_0 = kmeans.cluster_centers_[0]\ncentroid_1 = kmeans.cluster_centers_[1]\n\n# Plot both the centroid for cluster 0 and cluster 1 \nplt.scatter(centroid_0[0], centroid_0[1], color='red', marker='X', s=200, label='Centroid 0')\nplt.scatter(centroid_1[0], centroid_1[1], color='orange', marker='X', s=200, label='Centroid 1')\n\n## Put x label\nplt.xlabel(\"Hue\")\n## Put y label\nplt.ylabel(\"Saturation\")\n## Put title\nplt.title(\"K-Means Clustering of Face Hue and Saturation\")\n## Add a legend\nplt.legend()\n## Add grid\nplt.grid(True)\n## Show the plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-26T16:06:54.073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Read the class of the template image 'Dr_Shashi_Tharoor.jpg' using cv2 and store it in template_img\ntemplate_img = cv2.imread('Dr_Shashi_Tharoor.jpg')\n\n# Detect face in the template image after converting it to gray and store it in template_faces\ngray_template = cv2.cvtColor(template_img, cv2.COLOR_BGR2GRAY)\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\ntemplate_faces = face_cascade.detectMultiScale(gray_template, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n\n# Draw rectangles around the detected faces\nfor (x, y, w, h) in template_faces:\n    cv2.rectangle(template_img, (x, y), (x + w, y + h), (0, 255, 0), 3)\n\ncv2.imshow('Detected Faces', template_img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-26T16:06:54.073Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert the template image to HSV color space and store it in template_hsv\ntemplate_hsv = cv2.cvtColor(template_img, cv2.COLOR_BGR2HSV)\n\n# Extract hue and saturation features from the template image as we did it for detected faces.\ntemplate_hue = np.mean(template_hsv[:, :, 0])\ntemplate_saturation = np.mean(template_hsv[:, :, 1])\n\n# Predict the cluster label for the template image and store it in template_label\ntemplate_label = kmeans.predict([[template_hue, template_saturation]])[0]\n\n# Create a figure and axis for visualization\nfig, ax = plt.subplots(figsize=(12, 6))\n\n# Plot the clustered faces with custom markers (similar to previous code)\nfor i, (x, y, w, h) in enumerate(faces_rect):\n    color = 'red' if kmeans.labels_[i] == 0 else 'blue'\n    im = OffsetImage(cv2.cvtColor(cv2.resize(face_images[i], (20, 20)), cv2.COLOR_HSV2RGB))\n    ab = AnnotationBbox(im, (hue_saturation[i, 0], hue_saturation[i, 1]), frameon=False, pad=0)\n    ax.add_artist(ab)\n    plt.plot(hue_saturation[i, 0], hue_saturation[i, 1], 'o', markersize=5, color=color)\n\n# Plot the template image in the respective cluster\ncolor = 'red' if template_label == 0 else 'blue'\nim = OffsetImage(cv2.cvtColor(cv2.resize(template_img, (20, 20)), cv2.COLOR_BGR2RGB))\nab = AnnotationBbox(im, (template_hue, template_saturation), frameon=False, pad=0)\nax.add_artist(ab)\n\n## Put x label\nplt.xlabel(\"Hue\")\n## Put y label\nplt.ylabel(\"Saturation\")\n## Put title\nplt.title(\"K-Means Clustering of Face Hue and Saturation with Template Image\")\n## Add grid\nplt.grid(True)\n## Show plot\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-26T16:06:54.074Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create an empty list to store legend labels\nlegend_labels = []\n\n# Create lists to store points for each cluster\ncluster_0_points = []\ncluster_1_points = []\n\n# Your code for scatter plot goes here\nfig, ax = plt.subplots(figsize=(12, 6))\nfor i, (x, y, w, h) in enumerate(faces_rect):\n    if kmeans.labels_[i] == 0:\n        cluster_0_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n    else:\n        cluster_1_points.append((hue_saturation[i, 0], hue_saturation[i, 1]))\n\n# Plot points for cluster 0 in green\ncluster_0_points = np.array(cluster_0_points)\nplt.scatter(cluster_0_points[:, 0], cluster_0_points[:, 1], color='green', label='Cluster 0')\n\n# Plot points for cluster 1 in blue\ncluster_1_points = np.array(cluster_1_points)\nplt.scatter(cluster_1_points[:, 0], cluster_1_points[:, 1], color='blue', label='Cluster 1')\n\n# Calculate and plot centroids for both the clusters\ncentroid_0 = kmeans.cluster_centers_[0]\ncentroid_1 = kmeans.cluster_centers_[1]\nplt.scatter(centroid_0[0], centroid_0[1], color='red', marker='X', s=200, label='Centroid 0')  ## plot for centroid 0\nplt.scatter(centroid_1[0], centroid_1[1], color='orange', marker='X', s=200, label='Centroid 1')  ## plot for centroid 1\nplt.plot(template_hue, template_saturation, marker='o', c='violet', markersize=10, label='Class ?')\n\n## Put x label\nplt.xlabel(\"Hue\")\n## Put y label\nplt.ylabel(\"Saturation\")\n## Put title\nplt.title(\"K-Means Clustering of Face Hue and Saturation with Template Image\")\n## Add a legend\nplt.legend()\n## Add grid\nplt.grid(True)\n## Show the plot\nplt.show()\n\n## End of the lab 5 ##\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-26T16:06:54.074Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Report:\n## Answer the following questions within your report:\n","metadata":{}},{"cell_type":"markdown","source":"#### 1. What are the common distance metrics used in distance-based classification algorithms? \nAns: Common distance metrics in distance-based classification algorithms include Euclidean distance, Manhattan distance, Minkowski distance, and Cosine similarity. These metrics help determine the closeness of data points for classification.\n\n\n#### 2. What are some real-world applications of distance-based classification algorithms? \nAns: Real-world applications of distance-based classification algorithms include handwritten digit recognition (e.g., MNIST), medical diagnosis (disease prediction), recommendation systems, and fraud detection.\n\n#### 3. Explain various distance metrics. \nAns: Distance metrics:\nEuclidean Distance: Measures straight-line distance.\nManhattan Distance: Measures distance along axes (grid-like).\nMinkowski Distance: Generalized form of Euclidean and Manhattan.\nCosine Similarity: Measures angular similarity between vectors.\n\n#### 4. What is the role of cross validation in model performance? \nAns: Cross-validation helps assess model performance by dividing data into training and validation sets multiple times, ensuring the model generalizes well and reducing overfitting or underfitting risks.\n\n\n\n#### 5. Explain variance and bias in terms of KNN?\nAns: In KNN, high bias (low K) leads to overfitting, capturing noise, while high variance (high K) results in underfitting, making the model less sensitive to data patterns. A balanced K value is crucial.","metadata":{}}]}